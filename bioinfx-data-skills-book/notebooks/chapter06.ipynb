{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce4455d-d9d7-4c6e-9aff-915337b6934c",
   "metadata": {},
   "source": [
    "## Chapter 6. Bioinformatics data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1740404-481f-42af-9bd2-35fa9a1d9da9",
   "metadata": {},
   "source": [
    "### Retrieving Bioinformatics Data\n",
    "\n",
    "#### Downloading Data with wget and curl\n",
    "\n",
    "**wget:**\n",
    "`wget` is useful for quickly downloading a file from the command line — for example, human chromosome 22 from the GRCh37 (also known as hg19) assembly version:\n",
    "\n",
    "```bash\n",
    "wget http://hgdownload.soe.ucsc.edu/goldenPath/hg19/chromosomes/chr22.fa.gz\n",
    "```\n",
    "\n",
    "- In general, FTP is preferable to HTTP for large files (and is often recommended by websites like the UCSC Genome Browser).\n",
    "- One of `wget`’s strengths is that it can download data recursively. Running it with `--recursive` or `-r` option, `wget` will also follow and download the pages linked to, and even follow and download links on these pages (by default up to five links deep depth level can be set using `--level` or `-l` option).\n",
    "- We can ask `wget` to download only certain files that follow a pattern with `--accept` option and we can prevent it from downloading higher leverls using `--no-parent` option. See the example below:\n",
    "\n",
    "```bash\n",
    "  wget --accept \"*.gtf\" --no-directories --no-parent --recursive \\\n",
    "  http://genomics.someuniversity.edu/labsite/annotation.html\n",
    "```\n",
    "- In some cases, the remote host may block your IP address if you’re downloading too much too quickly. So beware when using `--recursive` option. However, for controlled downloading speed, we can set `--limit-rate` option accordingly not to exceed server download limits.\n",
    "- Here are some useful options for `wget` command:\n",
    "\n",
    "| Option | Values | Use|\n",
    "|--------|--------|----|\n",
    "|-A, --accept| Either a suffix like “.fastq” or a pattern with *, ?, or [ and ], optionally comma-<br>separated list | Only download files matching this criteria.|\n",
    "|-R, --reject | Same as with --accept | Don’t download files matching this; for example, to download all<br>files on a page except Excel files, use --reject \".xls\".|\n",
    "|-nd, --no-directory | No value | Don’t place locally downloaded files in same directory hierarchy as remote files.|\n",
    "|-r, --recursive| No value | Follow and download links on a page, to a maximum depth of five by default.|\n",
    "|-np, --no-parent| No value |Don’t move above the parent directory.|\n",
    "|--limit-rate | number of bytes to allow per second |Throttle download bandwidth.|\n",
    "|--user=user | FTP or HTTP username | Username for HTTP or FTP authentication.|\n",
    "|--ask-password | No value | Prompt for password for HTTP of FTP authentication; --password= could also be used, but then your password is in your shell’s history.|\n",
    "|-O | Output filename| Download file to filename specified; useful if link doesn’t have an informative name (e.g., http://lims.sequencingcenter.com/seqs.html?id=sample_A_03).|\n",
    "\n",
    "\n",
    "**Curl:**\n",
    "`curl` behaves similarly to `wget`, although by default writes the file to standard output. To download\n",
    "chromosome 22 as we did with wget, we’d use:\n",
    "\n",
    "```bash\n",
    "$ curl http://[...]/goldenPath/hg19/chromosomes/chr22.fa.gz > chr22.fa.gz\n",
    "```\n",
    "\n",
    "- We can set download file name using `-O <file_name>` option. If `<file_name>` is not provided, it will save it with its original name.\n",
    "- It can transfer files using more protocols than `wget` (e.g., `SFTP` (secure `FTP`) and `SCP` (secure copy).\n",
    "- `Curl` itself is also a library, meaning in addition to the command-line program, Curl’s functionality is wrapped by software libraries like `RCurl` and `pycurl`.\n",
    "\n",
    "**Note:** `wget` and `curl` are generally used to download individual files from a web server. When you use them on a GitHub URL, it's important to get the <u>raw file URL</u>, not the standard file or directory page URL. The standard URL for a file on GitHub leads to an HTML page with the file contents, not the file itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42eb41-970b-494c-8204-639745bce2f3",
   "metadata": {},
   "source": [
    "**Rsync and Secure Copy (scp):**\n",
    "\n",
    "While `wget` and `curl` are good for quickly downloading files from the commandline, for heavy-duty file transfers `Rsync` is better. Why:\n",
    "- Often faster because it only sends the difference between file versions.\n",
    "- Compresses files during transfers.\n",
    "- Has an archive option that preserves links, modification timestamps, permissions, ownership, and other file attributes.\n",
    "- Rsync basic command is `rsync source destination`, where `source` is the source of the files or directories you’d like to copy, and `destination` is the destination you’d like to copy these files to. Either `source` or `destination` can be a remote host specified in the format `user@host:/path/to/directory/`.\n",
    "- For remote source or destination, we need to provide connection protocol, like `ssh`, using `-e` option For example:\n",
    "\n",
    "```bash\n",
    "rsync -azv -e ssh source_dir/ user@host:path/to/dir\n",
    "```\n",
    "In above command, `-a` enables archive mode, `-z` enables file transfer compression, and `-v` enables verbosing. You can omit `-e ssh` if you connect to a host through an SSH host alias. Like below:\n",
    "\n",
    "```bash\n",
    "rsync -azv source_dir/ host_alis:path/to/dir\n",
    "```\n",
    "\n",
    "**Trailing slashes in rsync:**\n",
    "Trailing slashes (e.g., `data/` versus `data`) are meaningful when specifying paths in rsync. A trailing slash in the source path means copy the contents of the source directory, whereas no trailing slash means copy the entire directory itself.\n",
    "\n",
    "- rsync only only transmits files if they don’t exist or they’ve changed. Rerunning rsync will ensure everything is synchronized between the two directories.\n",
    "- If we are not transferring large files between source and densitation, using rsync is overkill. Instead, we can use `scp` like below:\n",
    "\n",
    "```bash\n",
    "scp source_dir/ user@host:path/to/dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a807e-3f61-45a6-bcc8-d11697434bcf",
   "metadata": {},
   "source": [
    "### Data Integrity\n",
    "\n",
    "#### Checksums\n",
    "- Used for checking transferred data's integrity.\n",
    "- Are very compressed summaries of data, which would reflect chnages as small as one bit of the data.\n",
    "- Are also helpful for keeping tracks of data versions, such as intermediate data.\n",
    "- Facilitate reproducibilty\n",
    "\n",
    "#### SHA and MD5 Checksums\n",
    "- Two most common checksum algorithms. For example, Git commit IDs use SHA-1 checksum.\n",
    "- SHA-1 is newer than MD5 and is preferred but MD5 is more common.\n",
    "- We can use `md5sum` or `shasum` to generate checkcums for files.\n",
    "\n",
    "```bash\n",
    "echo \"bioinformatics is fun\" | md5sum  # using md5sum\n",
    "echo \"bioinformatics is fun\" | shasum  # using shasum\n",
    "```\n",
    "- Are reported in hexadecimal format, where each digit can be one of 16 characters: digits 0\n",
    "through 9, and the letters a, b, c, d, e, and f.\n",
    "- The trailing dash indicates this is the SHA-1 checksum of input from <u>standard in</u>, otherwise there is no trailing dash we use file as an input.\n",
    "- When we have many files, `shasum` can create and validate against a file containing the checksums of files. For example, for fastq files in `data/` directory, we can run:\n",
    "\n",
    "```bash\n",
    "shasum data/*fastq > fastq_checksums.sha\n",
    "```\n",
    "\n",
    "- We can use shasum’s check option (`-c`) to validate that these files match the original versions:\n",
    "\n",
    "```bash\n",
    "$ shasum -c fastq_checksums.sha\n",
    "```\n",
    "\n",
    "- Some servers use an antiquated checksum implementation such as `sum` or `chsum`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d7993-5bcb-477b-817f-670d1e7ec2e7",
   "metadata": {},
   "source": [
    "### Looking at Differences Between Data\n",
    "\n",
    "#### Unix tool `diff`\n",
    "\n",
    "- Unix’s `diff` works line by line, and outputs blocks (called hunks) that differ between files.\n",
    "\n",
    "```bash\n",
    "diff -u file1 file2\n",
    "```\n",
    "`-u` option is short for unified format, which is similar to Git's `diff` subcommand's output's format.\n",
    "\n",
    "Here is the breakdown of `diff`'s output (in unified format):\n",
    "\n",
    "<img src=\"images/diff_output.png\" width=500>\n",
    "\n",
    "1. These two lines are the header of the unified diff. The original file `gene-1.bed` is prefixed by `---`, and the modified file `gene-2.bed` is prefixed by `+++`. The date and time in these two lines are the modification times of these files.\n",
    "2. This line indicates the start of a changed hunk. The pairs of integers between `@@` and `@@` indicate where the hunk begins, and how long it is, in the original file `(-1,22)` and modified file `(+1,19)`, respectively.\n",
    "3. Lines in the diff that begin with a space indicate the modified file’s line hasn’t changed.\n",
    "4. Lines in the diff that begin with a + indicate a line has been added to the modified file.\n",
    "5. Similarly, - indicates lines removed in the modified file.\n",
    "6. An adjacent line deletion and line addition indicates that this line was changed in the modified file.\n",
    "\n",
    "- `diff`’s output can also be redirected to a file, which creates a `patch file`.\n",
    "- Patch files act as instructions on how to update a plain-text file, making the changes contained in the diff file.\n",
    "- The Unix tool `patch` can apply changes to a file needed to be patched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee1e65-ff97-4fe2-a9ce-9597080e5a2c",
   "metadata": {},
   "source": [
    "### Compressing Data and Working with Compressed Data\n",
    "\n",
    "- Using pipes and redirection, we can stream compressed data and write compressed files directly to the disk.\n",
    "- Common Unix tools like `cat`, `grep`, and `less` all have variants that work with compressed data.\n",
    "- Python’s `gzip` module allows us to read and write compressed data from within Python.\n",
    "\n",
    "#### gzip vs bzip2\n",
    "\n",
    "| Feature | Gzip | Bzip2 |\n",
    "| :--- | :--- | :--- |\n",
    "| **Speed** | Faster compression and decompression | Slower compression and decompression |\n",
    "| **Compression Ratio**| Good | Better (smaller file sizes) |\n",
    "| **Common Use** | Bioinformatics, general-purpose compression | Long-term data archiving |\n",
    "| **Tools** | `gzip`, `gunzip` | `bzip2`, `bunzip2` |\n",
    "\n",
    "**Difference between `gzip` and `gunzip`**\n",
    "\n",
    "While `gzip` (which stands for \"GNU zip\") compresses files and adds a `.gz` extension, `gunzip` reverses the process to restore the original file. On most Unix-like systems, `gunzip` is a simple alias for running `gzip -d` (the decompress flag).\n",
    "\n",
    "Here is an example of using `gzip` to compresse output of an imaginary program `trimmer`:\n",
    "\n",
    "```bash\n",
    "trimmer in.fastq.gz | gzip > out.fastq.gz\n",
    "```\n",
    "\n",
    "- `gzip` also can compress files on disk in place: `gzip file`, which will ouptut `file.gz`.\n",
    "- A nice feature of the gzip compression algorithm is that you can concatenate gzip compressed output directly to an existing gzip file.\n",
    "\n",
    "```bash\n",
    "cat *.gz > combined.gz\n",
    "```\n",
    "\n",
    "- If you need to compress multiple separate files into a single archive, use the `tar` utility.\n",
    "\n",
    "#### Working with Gzipped Compressed Files\n",
    "\n",
    "- Many common Unix and bioinformatics tools can work directly with compressed files.\n",
    "- If programs cannot handle compressed input, you can use `zcat` and pipe output directly to the standard input of another program.\n",
    "- There can be a slight performance cost in working with gzipped files, as your CPU must decompress input first. Usually, the convenience of z-tools like `zgrep`, `zless`, and `zcat` and the saved disk space outweigh any potential performance hits.\n",
    "\n",
    "Here's a table summarizing the GNU tools and their compressed file counterparts.\n",
    "\n",
    "| Command | Counterpart for `.gz` files | Counterpart for `.bz2` files | Counterpart for `.xz` files |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **`cat`** | `zcat` | `bzcat` | `xzcat` |\n",
    "| **`grep`** | `zgrep` | `bzgrep` | `xzgrep` |\n",
    "| **`less`** | `zless` | `bzless` | `xzless` |\n",
    "| **`diff`** | `zdiff` | `bzdiff` | `xzdiff` |\n",
    "\n",
    "---\n",
    "**Key Takeaways**\n",
    "\n",
    "The **`z`**, **`bz`**, and **`xz`** prefixes are a common GNU convention for handling compressed files directly. These tools work by decompressing the input on the fly and then performing their standard function, like searching (`grep`), viewing (`less`), or comparing (`diff`). This saves you a step by eliminating the need to manually decompress the file before using the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8888e3-3a52-4fb3-a3d7-becbe73d12ae",
   "metadata": {},
   "source": [
    "### Case Study: Reproducibly Downloading Data\n",
    "\n",
    "- Genomes releases are coordinated through the Genome Reference Consortium. The “GRC” prefix in `GRCm39` refers to the **Genome Reference Consortium**.\n",
    "\n",
    "- Downloaded mouse genome GRCm39 and checksums from Ensembl's FTP site:\n",
    "\n",
    "```bash\n",
    "wget -A \"*.fa.gz\", \"CHECKSUMS\" -np -nd -r -N ftp://ftp.ensembl.org/pub/current_fasta/mus_musculus/dna_index/\n",
    "```\n",
    "\n",
    "- Ran a quick sanity check to see if the file contains chromosomes, contigs, and scaffolds:\n",
    "\n",
    "```bash\n",
    "zgrep \"^>\" Mus_musculus.GRCm39.dna.toplevel.fa.gz | less\n",
    "```\n",
    "| Feature | Contigs | Scaffolds |\n",
    "| :--- | :--- | :--- |\n",
    "| **Structure** | Continuous sequence with no gaps. | Composed of multiple contigs separated by gaps. |\n",
    "| **Gaps** | No gaps. | Contains gaps of estimated length. |\n",
    "| **Assembly Level**| The most basic, fundamental assembled unit. | A higher-level structure that links multiple contigs. |\n",
    "| **Information** | Based on direct overlapping sequence reads. | Uses additional long-range information to order contigs. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
