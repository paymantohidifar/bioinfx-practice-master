{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1df6b7d-8ee2-4d45-937f-823a4cb2a956",
   "metadata": {},
   "source": [
    "# Chapter 8: A Rapid Introduction to the R Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0227f63-77ed-4e0d-b5cc-7c2092214a6c",
   "metadata": {},
   "source": [
    "## R Language Basics\n",
    "\n",
    "### Significant Digits, print(), and Options in R\n",
    "\n",
    "- By default, R will print seven significant digits.\n",
    "- You can use `print()` function to define number of digits.\n",
    "\n",
    "```r\n",
    "print(sqrt(3.5), digits = 10) \n",
    "```\n",
    "\n",
    "- `getOption('digits')`: Get default global number of significant digits in R\n",
    "- `options(digit=9)`: Set default global number of significant digits in R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0af6b2-5af2-4694-a1cb-58385c00266c",
   "metadata": {},
   "source": [
    "### Getting help in R\n",
    "\n",
    "- `help()` or `?`: Access R’s built-in documentation with:\n",
    "\n",
    "```R\n",
    "help(log)\n",
    "?log\n",
    "```\n",
    "- `help.search()` or `??`: Get help using a definition of a task (e.g., what was the function in R that calculates cross tabulate vectors??)\n",
    "\n",
    "```R\n",
    "help.search(\"cross tabulate\")\n",
    "??\"cross tabulate\"\n",
    "```\n",
    "\n",
    "- `example()`: Executes all examples in a R help file\n",
    "\n",
    "```R\n",
    "example(log)\n",
    "```\n",
    "\n",
    "- `library(help=\"package_name\")`: Lists all functions in a package\n",
    "- `apropos(\"part_of_func_name\")`: Finds functions by name\n",
    "\n",
    "```R\n",
    "library(help=\"base\") # List all functions in base\n",
    "apropos(\"norm\"): # Finds norm function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b3a3e-3bf1-4545-9d0f-695aa4e84b88",
   "metadata": {},
   "source": [
    "### Variables and Assignment\n",
    "\n",
    "When we assign a value in our R session, we’re assigning it to an *environment* known as the *global environment*. We can see objects we’ve created in the global environment\n",
    "with the function `ls()`:\n",
    "\n",
    "- `ls()`: Lists objects created in the global environment\n",
    "- `search()`: Returns where R looks when searching for the value of a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b473d-800d-4e9d-a255-e65f14a219d0",
   "metadata": {},
   "source": [
    "### Vectors, Vectorization, and Indexing\n",
    "\n",
    "- A vector is a container of contiguous data.\n",
    "- `length()`: Returns length of a vector.\n",
    "- `c()`: Creates a vector by combining values (of same type): `x <- c(1, 2, 3)`\n",
    "- R’s vectors are the basis of one of R’s most important features: vectorization. Vectorization allows us to loop over vectors elementwise, without the need to write an explicit loop.\n",
    "- `seq()` or `:`: Creates integer sequences: `seq(3,6)` or `3:6`\n",
    "- If one vector is longer than the other, R will recycle the values in the shorter vector:\n",
    "\n",
    "```R\n",
    "c(1, 2) + c(0, 0, 0, 0)\n",
    "[1] 1 2 1 2\n",
    "c(1, 2) + c(0, 0, 0)\n",
    "[1] 1 2 1\n",
    "Warning message:\n",
    "In c(1, 2) + c(0, 0, 0) :\n",
    "longer object length is not a multiple of shorter object length\n",
    "```\n",
    "\n",
    "- In addition to operators like `+` and `*`, many of R’s mathematical functions (e.g.,`sqrt()`, `round()`, `log()`, etc.) are all vectorized.\n",
    "- We can access specific elements of a vector through *indexing*. R’s vectors are 1-indexed, meaning that the index 1 corresponds to the first element in a list (in contrast to 0-indexed languages like Python).\n",
    "- Trying to access an element that doesn’t exist in the vector leads R to return `NA`, the “not available” missing value.\n",
    "- Vectors can also have names, which you can set while combining values with `c()`. Or we can use `names()` function to add names to a vector's elements:\n",
    "\n",
    "```R\n",
    "x <- c(a=1, b=3)\n",
    "y <- c(1,2,3)\n",
    "names(y) <- c(\"a\", \"b\", \"c\")\n",
    "```\n",
    "\n",
    "- And just as we can access elements by their positional index, we can also access them by their name: `x['a']`.\n",
    "- It is also possible to extract more than one element simultaneously from a vector using indexing: `x[1:2]` or `x[c(1,2)]`.\n",
    "- It’s also possible to exclude certain elements from lists using negative indexes:\n",
    "\n",
    "```R\n",
    "z[c(-4, -5)] # exclude fourth and fifth elements\n",
    "[1] 3.4 2.2 0.4 \n",
    "```\n",
    "\n",
    "- We could reverse the elements of a vector by creating the sequence of integers from 5 down to 1 using `5:1`:\n",
    "\n",
    "```R\n",
    "z <- c(3.4, 2.2, 0.4, -0.4, 1.2)\n",
    "z[5:1]\n",
    "[1] 1.2 -0.4 0.4 2.2 3.4\n",
    "```\n",
    "\n",
    "- The function `order()` returns a vector of indexes that indicate the (ascending) order of the elements. We can use `order()` to sort a vector:\n",
    "\n",
    "```R\n",
    "x <- c(2.3, 3.4, -1)\n",
    "x[order(x, decreasing = TRUE)]\n",
    "# [1]  3.4  2.3 -1.0\n",
    "x[order(x, decreasing = FALSE)]\n",
    "# [1] -1.0  2.3  3.4\n",
    "```\n",
    "\n",
    "- Often we use functions to generate indexing vectors for us. For example, one way to resample a vector (with replacement) is to randomly sample its indexes using the `sample()` function:\n",
    "\n",
    "```R\n",
    "set.seed(0)\n",
    "    z <- c(3.4, 2.2, 0.4, -0.4, 1.2)\n",
    "# we set the random number seed so this example is reproducible\n",
    "i <- sample(length(z), replace=TRUE)\n",
    "i\n",
    "# [1] 5 2 2 3 5\n",
    "z[i]\n",
    "# [1] 1.2 2.2 2.2 0.4 1.2\n",
    "```\n",
    "\n",
    "Here is R’s comparison and logical operators:\n",
    "\n",
    "| Operator | Description |\n",
    "|----------| ------------|\n",
    "| >        | Greater than |\n",
    "| <        |Less than    |\n",
    "| >=       | Greater than or equal to |\n",
    "|<=        | Less than or equal to |\n",
    "| ==       | Equal to |\n",
    "|!         | Not equal to |\n",
    "| &        | Elementwise logical AND |\n",
    "|\\|        | Elementwise logical OR |\n",
    "|!         | Elementwise logical NOT |\n",
    "|&&        | Logical AND (first element only, for if statements) |\n",
    "|\\|\\|      | Logical OR (first element only, for if statements) |\n",
    "\n",
    "\n",
    "Table 8-3. R’s vector types:\n",
    "\n",
    "|Type | Example | Creation function | Test function | Coercion function |\n",
    "|-----| --------| ----------------- | ------------- | ----------------- |\n",
    "| Numeric | c(23.1, 42, -1) | numeric() | is.numeric() | as.numeric() |\n",
    "| Integer | c(1L, -3L, 4L) | integer() | is.integer() | as.integer() |\n",
    "| Character |c(\"a\", \"c\") | character() | is.character() | as.character() |\n",
    "| Logical | c(TRUE, FALSE) | logical() | is.logical() | as.logical() |\n",
    "\n",
    "R has four special values used to represent different types of data states:\n",
    "\n",
    "* **NA** stands for \"not available\" and signifies **missing data**. Operations involving NA typically result in NA. You can check for NA values using the `is.na()` function.\n",
    "* **NULL** represents the **absence of a value** altogether, which is distinct from a missing value. The `is.null()` function is used to test for NULL.\n",
    "* **Inf** and **-Inf** denote **positive and negative infinity**, respectively. You can use the `is.infinite()` function to check for these values.\n",
    "* **NaN** stands for \"not a number\" and results from **mathematical computations that produce an undefined numerical value**, such as dividing zero by zero. The `is.nan()` function checks for these values.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e15b0-1c06-4ddc-8d5b-e954ad7be4ff",
   "metadata": {},
   "source": [
    "### Factors and classes in R\n",
    "\n",
    "Factors store categorical variables, such as a treatment group (e.g., “high,” “medium,” “low,” “control”), strand (forward or reverse), or chromosome (“chr1,” “chr2,” etc.).\n",
    "\n",
    "- We can create a factor from a vector using the function `factor()`:\n",
    "\n",
    "```R\n",
    "chr_hits <- c(\"chr2\", \"chr2\", \"chr3\", \"chrX\", \"chr2\", \"chr3\", \"chr3\")\n",
    "hits <- factor(chr_hits)\n",
    "hits\n",
    "# [1] chr2 chr2 chr3 chrX chr2 chr3 chr3\n",
    "# Levels: chr2 chr3 chrX\n",
    "```\n",
    "\n",
    "- The levels are the possible values a factor can contain (these are fixed and must be unique). We can view a factor’s levels by using the function `levels()`:\n",
    "\n",
    "```R\n",
    "levels(hits)\n",
    "# [1] \"chr2\" \"chr3\" \"chrX\"\n",
    "```\n",
    "\n",
    "- We can count up how many of each level there are in a factor using the function `table()`:\n",
    "\n",
    "```R\n",
    "table(hits)\n",
    "# hits\n",
    "# chrX chrY chr2 chr3 chr4\n",
    "#    1    0    3    3    0\n",
    "```\n",
    "\n",
    "- To discern the difference between an object’s class and its type, notice that factors are just integer vectors under the hood:\n",
    "\n",
    "```R\n",
    "typeof(hits)\n",
    "# [1] \"integer\"\n",
    "as.integer(hits)\n",
    "# [1] 3 3 4 1 3 4 4\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c17d11-b3bc-4db9-8fd4-9cb9dfc50d2c",
   "metadata": {},
   "source": [
    "## Working with and Visualizing Data in R\n",
    "\n",
    "### Loading Data into R\n",
    "\n",
    "You can use `getwd()` to get R’s current working directory and `setwd()` to set the working directory:\n",
    "\n",
    "```R\n",
    "getwd()\n",
    "# [1] \"/home/payman\"\n",
    "setwd(\"~/bds-files/chapter-08-r\") # path to this chapter's\n",
    "# directory in the Github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6043ce-7419-43fd-8798-0bd2148a5729",
   "metadata": {},
   "source": [
    "### Loading Large Genomics Data in R\n",
    "\n",
    "* **Reduce data size:** If a dataset is too large to fit in your computer's memory, you should reduce its size before loading it. You can do this by summarizing the data, omitting unnecessary columns, splitting the data into smaller chunks, or using a random subset.\n",
    "\n",
    "* **Speed up loading:** If the data fits in memory but takes a long time to load, you can significantly speed up the process by using the `colClasses` argument in R's data-reading functions (`read.csv()`, `read.delim()`).\n",
    "\n",
    "* **Specify data types:** Explicitly setting the data type for each column with the `colClasses` argument saves R time.\n",
    "\n",
    "* **Skip columns:** Use `\"NULL\"` for the value in `colClasses` to tell R to skip columns you don't need, which saves both time and memory.\n",
    "\n",
    "* **Specify the number of rows**: You can improve the performance of `read.delim()` by setting the `nrow` argument, which tells R how many rows to expect. An easy way to estimate this number is by using the `wc -l` command. It's fine to slightly overestimate this value.\n",
    "\n",
    "* **Use `data.table::fread()`**: For a significant speed boost, consider using the `fread()` function from the `data.table` package. It is much faster than the standard `read.*` functions but returns a `data.table` object, which behaves differently from a standard `data.frame`.\n",
    "\n",
    "* **Use SQLite for very large data**: If your data is too big for your computer's memory, you can use a database solution like SQLite. The **RSQLite** R package allows you to store the data on disk and query subsets for analysis, avoiding the need to load the entire dataset into memory.\n",
    "\n",
    "* **Work with compressed files**: R's data-reading functions can directly read gzipped files (files ending in `.gz`), eliminating the need to uncompress them first. This saves disk space and can offer slight performance gains due to fewer bytes being read from the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a284d-22c6-4505-a2a3-47a7eaded4a4",
   "metadata": {},
   "source": [
    "### Reading data tables in R\n",
    "\n",
    "- `read.csv()`: Used for reading CSV files\n",
    "- `read.delim()`: Used for reading tab-delimited files\n",
    "- Both functions are thin wrappers around the function `read.table()` with the proper arguments set for CSV and tab-delimited files.\n",
    "\n",
    "```R\n",
    "d <- read.csv(\"file.csv\")\n",
    "bd <- read.delim(\"noheader.bed\", header=FALSE, col.names=c(\"chrom\", \"start\", \"end\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f0051-9fe4-4708-83bd-c09ba5404565",
   "metadata": {},
   "source": [
    "### Getting Data into Shape\n",
    "\n",
    "In many cases, data is recorded by humans in wide format, but we need data in long format when working with and plotting statistical modeling functions. Hadley Wickham’s `reshape2` package provides functions to reshape data: **the function `melt()` turns wide data into long data, and `cast()` turns long data into wide data.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828943b9-22b8-4bb1-b579-adda07290dda",
   "metadata": {},
   "source": [
    "### Exploring and Transforming Dataframes\n",
    "\n",
    "- `read.csv()` output is stored as a *dataframe*.\n",
    "- Each of the columns of a dataframe are vectors.\n",
    "\n",
    "Some useful functions to analyse a dataframe:\n",
    "- `head(df, n=XX)`: Returns XX frist rows of the dataframe\n",
    "- `nrow(df)`: Number of rows\n",
    "- `ncol(df)`: Number of columns\n",
    "- `dim(df)`: Dimension of dataframe\n",
    "- `rownames(df)`: names of rows\n",
    "- `colnames(df)`: names of columns\n",
    "- `df$col_name` or `df[\"col_name\"]`: Access to a single column\n",
    "- `df[,1:2]`: access entire columns 1 and 2\n",
    "- `df[,c(\"col1\", \"col2\")]`: access entire \"col1\" and \"col2\"\n",
    "- `df[1, ]`: access entire row 1\n",
    "- `df[1,2]`: access cell from row 1 and column 2\n",
    "- `df[, \"start\", drop=FALSE]`: returns the column as dataframe not a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb815a4a-ead7-4721-983f-666e572cd925",
   "metadata": {},
   "source": [
    "### Creating Dataframes from Scratch\n",
    "\n",
    "You can do this with the function `data.frame()`, which creates a dataframe from vector arguments (recycling the shorter vectors when necessary)\n",
    "\n",
    "```R\n",
    "x <- sample(1:50, 300, replace=TRUE)\n",
    "y <- 3.2*x + rnorm(300, 0, 40)\n",
    "d_sim <- data.frame(y=y, x=x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371fa994-c30b-45d3-ab48-40c70137dd16",
   "metadata": {},
   "source": [
    "### Exploring Data Through Slicing and Dicing: Subsetting Dataframes\n",
    "\n",
    "- In these examples, we’re extracting all columns by omitting the column argument in the bracket operator (e.g., col in `df[row, col]`). If we only care about a few particular columns, we could specify them by their position or their name:\n",
    "\n",
    "```R\n",
    "d[d$Pi > 16 & d$percent.GC > 80, c(\"start\", \"end\", \"depth\", \"Pi\")]\n",
    "#          start      end epth     Pi\n",
    "# 58550 63097001 63098000 2.39 41.172\n",
    "# 58641 63188001 63189000 3.21 16.436\n",
    "# 58642 63189001 63190000 1.89 41.099\n",
    "```\n",
    "\n",
    "- It’s also possible to subset rows by referring to their integer positions. The function `which()` takes a vector of logical values and returns the positions of all TRUE values.\n",
    "- `which()` also has two related functions that return the index of the first minimum or maximum element of a vector: `which.min()` and `which.max()`. For example:\n",
    "\n",
    "```R\n",
    "d[which.min(d$total.Bases),]\n",
    "#         start      end total.SNPs total.Bases depth [...]\n",
    "#25689 25785001 25786000          0         110  1.24 [...]\n",
    "d[which.max(d$depth),]\n",
    "#        start     end total.SNPs total.Bases depth [...]\n",
    "# 8718 8773001 8774000         58      21914  21.91 [...]\n",
    "```\n",
    "\n",
    "- `subset()`: A useful convenience function (intended primarily for interactive use). It takes two arguments: the dataframe to operate on, and then conditions to include a row.\n",
    "\n",
    "```R\n",
    "subset(d, Pi > 16 & percent.GC > 80)\n",
    "#          start      end total.SNPs total.Bases depth [...]\n",
    "# 58550 63097001 63098000          5         947  2.39 [...]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b1dac-74da-4b31-b945-0eae4dc16f4f",
   "metadata": {},
   "source": [
    "### Exploring Data Visually with ggplot2 I: Scatterplots and Densities\n",
    "\n",
    "- The best up-to-date reference for ggplot2 is [the ggplot2 online documentation](http://docs.ggplot2.org/).\n",
    "- Recommend books\n",
    "    - **ggplot2: Elegant Graphics for Data Analysis** by Hadley Wickham (Springer, 2010)\n",
    "    - **R Graphics Cookbook** by Winston Chang (O’Reilly, 2012)\n",
    "\n",
    "- To install and load `ggplot2` package in R:\n",
    "\n",
    "```R\n",
    "install.packages(\"ggplot2\")\n",
    "library(ggplot2)\n",
    "```\n",
    "\n",
    "- Each `ggplot2` plot is built by adding layers to a plot that map the *aesthetic properties* of *geometric objects* to data. Layers can also apply statistical transformations to data and change the scales of axes and colors.\n",
    "- We specify the mapping of aesthetic attributes to columns in our dataframe using the function `aes()`.\n",
    "- `ggplot2` works exclusively with **dataframes**, so you’ll need to get your data tidy and into a dataframe before visualizing it with ggplot2.\n",
    "\n",
    "```R\n",
    "d$position <- (d$end + d$start) / 2\n",
    "p <- ggplot(d) + geom_point(aes(x=position, y=diversity))\n",
    "```\n",
    "\n",
    "- Aesthetic mappings can also be specified in the call to `ggplot()` — geoms will then use\n",
    "this mapping.\n",
    "\n",
    "```R\n",
    "p <- ggplot(d, aes(x=position, y=diversity)) + geom_point()\n",
    "```\n",
    "\n",
    "- `ggplot2` has many geoms (e.g., `geom_line()`, `geom_bar()`, `geom_density()`, `geom_boxplot()`, etc.)\n",
    "- **Labels and Title**: You can change the default axis labels and add a title using specific functions:\n",
    "    - `xlab()` for the x-axis label.\n",
    "    - `ylab()` for the y-axis label.\n",
    "    - `ggtitle()` for the main plot title.\n",
    "\n",
    "    ```R\n",
    "    p <- p + xlab(\"xlabel\") + ylab(\"ylabel\") + ggtitle(\"Title\")\n",
    "    ```\n",
    "- **Axis Scales**: You can control the range and transformation of continuous axes:\n",
    "    - `scale_x_continuous(limits = c(start, end))` and `scale_y_continuous()` let you manually set the start and end points of the axes.\n",
    "    - `scale_x_log10()` and `scale_y_log10()` transform the axes to a log base 10 scale.\n",
    "- We can map color to a column using `aes()` function:\n",
    "\n",
    "```R\n",
    "p <- ggplot(d, aes(x=position, y=diversity, color=cent)) + geom_point()\n",
    "```\n",
    "\n",
    "- We can use plot dessity using `geom_density()` layer:\n",
    "\n",
    "```R\n",
    "ggplot(d) + geom_density(aes(x=diversity, color=cent), fill=\"black\", alpha=0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b77f47-d903-4bc9-8f8b-d697a9287706",
   "metadata": {},
   "source": [
    "### Exploring Data Visually with ggplot2 II: Smoothing\n",
    "\n",
    "There are numerous potential confounders in genomic data (e.g., sequencing read depth; GC content; mapability, or whether a region is capable of having reads correctly align to it; batch effects; etc.)\n",
    "\n",
    "```R\n",
    "ggplot(d, aes(x=depth, y=total.SNPs)) + geom_point() + geom_smooth()\n",
    "```\n",
    "\n",
    "- By default, `ggplot2` uses generalized additive models (GAM) to fit this smoothed curve for datasets with more than 1,000 rows.\n",
    "- `ggplot2` adds confidence intervals around the smoothing curve; this can be disabled by using `geom_smooth(se=FALSE)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25617bf4-4b2d-4c6c-836e-39d1e45acb92",
   "metadata": {},
   "source": [
    "### Binning Data with cut() and Bar Plots with ggplot2\n",
    "\n",
    "- Binning takes continuous numeric values and places them into a discrete number of ranged bins.\n",
    "- The benefit is that discrete bins facilitate conditioning on a variable. Conditioning is an incredibly powerful way to reveal patterns in data.\n",
    "- `cut()`: Bins data\n",
    "\n",
    "```R\n",
    "d$GC.binned <- cut(d$percent.GC, 5) # Number of breaks=5\n",
    "d$GC.binned <- cut(d$percent.GC, c(0, 25, 50, 75, 100)) # we can directly specify breaks\n",
    "```\n",
    "\n",
    "- When you manually specify breaks that don’t fully enclose all values, values outside the range of breaks will be given the value NA. You can check if your manually specified breaks have created NA values\n",
    "using `any(is.na(cut(x, breaks)))`\n",
    "- We can plot binned columns usig `geom_bar()` layer:\n",
    "\n",
    "```R\n",
    "ggplot(d) + geom_bar(aes(x=d$GC.binned))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e7c26-86f3-4bdb-a9e1-bf461a5eddd9",
   "metadata": {},
   "source": [
    "### Merging and Combining Data: Matching Vectors and Merging Dataframes\n",
    "\n",
    "* `x %in% y`: Returns a logical vector indicating which of the values of x are in y.\n",
    "\n",
    "```R\n",
    "> c(3, 4, -1) %in% c(1, 3, 4, 8)\n",
    "# [1] TRUE TRUE FALSE\n",
    "```\n",
    "\n",
    "Let's show how to select desired rows using `%in%`:\n",
    "\n",
    "```R\n",
    "reps <- read.delim(\"chrX_rmsk.txt.gz\", header=TRUE) # Repeat data found by Repeat Masker\n",
    "common_reps <- c(\"SINE\", \"LINE\", \"LTR\", \"DNA\", \"Simple_repeat\")\n",
    "reps[reps$repClass %in% common_reps, ]\n",
    "```\n",
    "\n",
    "* `match(x, y)`: Returns the first occurrence of each of x’s values in y. If `match()` can’t find one of x’s elements in y, it returns its nomatch argument (which by default has the value NA).\n",
    "\n",
    "* **Merging DataFrames with `match()`**: The `match()` function in R can be used to combine two data frames, acting similarly to a left outer join. It finds the positions of elements from one data frame (`mtfs$pos`) within a second data frame (`rpts$pos`).\n",
    "\n",
    "```bash\n",
    "i <- match(mtfs$pos, rpts$pos)\n",
    "```\n",
    "\n",
    "* **Handling Missing Data**: Positions from the first data frame (`mtfs`) that don't have a corresponding match in the second (`rpts`) will result in `NA` values in the merged column. The `table(is.na(i))` command can be used to count how many matches were found versus how many were not.\n",
    "\n",
    "```bash\n",
    "table(is.na(i))\n",
    "```\n",
    "\n",
    "* **Performing an Outer Join**: The new column, in this case `mtfs$repeat_name`, is created by using the index vector generated by `match()` to select the appropriate values from the second data frame (`rpts$name`) and assign them to the first (`mtfs`).\n",
    "\n",
    "```bash\n",
    "mtfs$repeat_name <- rpts$name[match(mtfs$pos, rpts$pos)]\n",
    "```\n",
    "\n",
    "* **Performing an Inner Join**: To perform an inner join, where only rows with matching data are kept, you can filter out the `NA` values from the merged data frame. The example uses `mtfs_inner <- mtfs[!is.na(mtfs$repeat_name), ]` to achieve this.\n",
    "\n",
    "```bash\n",
    "mtfs_inner <- mtfs[!is.na(mtfs $repeat_name), ]\n",
    "```\n",
    "\n",
    "\n",
    "The `merge()` function in R is a user-friendly way to combine two data frames. By default, it performs a join similar to an **inner join**, keeping only the rows where the specified columns have matching values in both data frames.\n",
    "\n",
    "```bash\n",
    "recm <- merge(mtfs, rpts, by.x=\"pos\", by.y=\"pos\") \n",
    "```\n",
    "\n",
    "#### Key Features of `merge()`\n",
    "\n",
    "* **Specify Columns**: It's best practice to explicitly name the columns to merge by using the `by.x` and `by.y` arguments. For instance, `by.x=\"pos\"` and `by.y=\"pos\"` tells R to find matching values in the `pos` column of both data frames.\n",
    "* **Different Types of Joins**:\n",
    "    * **Inner Join (Default)**: Combines rows that have matching values in both data frames. This is the default behavior.\n",
    "    * **Left Outer Join**: Use `all.x=TRUE` to keep all rows from the first data frame (`x`) and include matching rows from the second (`y`). Unmatched rows from `y` will show `NA`.\n",
    "    * **Right Outer Join**: Use `all.y=TRUE` to keep all rows from the second data frame (`y`) and include matching rows from the first (`x`).\n",
    "    * **Full Outer Join**: Use `all=TRUE` to keep all rows from both data frames, filling in `NA`s where there are no matches.\n",
    "* **Avoiding Duplicates**: The `merge()` function can sometimes create duplicated columns (e.g., `chr.x` and `chr.y`) if a column name exists in both data frames but isn't used for merging. For this reason, sometimes a custom approach with `match()` can be more efficient if you want to avoid these extra columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba0ec7-d6e2-415d-bbca-876b8ab2041b",
   "metadata": {},
   "source": [
    "### Using ggplot2 Facets\n",
    "\n",
    "* `ggplot2` has two facet methods: `facet_wrap()` and `facet_grid()`\n",
    "* `facet_wrap()` takes a factor column and creates a panel for each level and wraps around horizontally.\n",
    "\n",
    "```bash\n",
    "> p <- ggplot(mtfs, aes(x=dist, y=recom)) + geom_point(size=1, color=\"grey\")\n",
    "> p <- p + geom_smooth(method='loess', se=FALSE, span=1/10)\n",
    "> p <- p + facet_wrap(~ motif)\n",
    "> print(p)\n",
    "```\n",
    "\n",
    "* `facet_grid()` allows finer control of facets by allowing you to specify the columns to use for vertical and horizontal facets. For example:\n",
    "\n",
    "```bash\n",
    "> p <- ggplot(mtfs, aes(x=dist, y=recom)) + geom_point(size=1, color=\"grey\")\n",
    "> p <- p + geom_smooth(method='loess', se=FALSE, span=1/16)\n",
    "> p <- p + facet_grid(repeat_name ~ motif)\n",
    "> print(p)\n",
    "```\n",
    "\n",
    "`ggplot2`'s `facet_wrap()` and `facet_grid()` functions use the tilde (`~`) symbol to specify the variables for creating separate plots. This syntax comes from R's formula notation, commonly used in statistical models.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "* **Tilde (`~`) Syntax**: The tilde is used to define the faceting variable. For example, `facet_wrap(~variable_name)` tells `ggplot2` to create a new panel for each unique value in `variable_name`.\n",
    "* **Fixed Scales (Default)**: By default, both `facet_wrap()` and `facet_grid()` use **fixed scales** for the x and y axes. This means all the individual plots share the same axis limits, which is useful for direct visual comparisons between panels.\n",
    "* **Free Scales**: To allow each panel to have its own unique axis limits, you can change the `scales` argument:\n",
    "    * `scales = \"free_x\"`: Frees the x-axis, allowing each plot to have its own x-axis range.\n",
    "    * `scales = \"free_y\"`: Frees the y-axis, allowing each plot to have its own y-axis range.\n",
    "    * `scales = \"free\"`: Frees both the x and y axes, giving each plot a unique range for both.\n",
    "\n",
    "Using free scales can be helpful when a fixed scale would hide important patterns in the data due to large differences in magnitude between panels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd464ac-65b1-455a-b5ca-29312a4a1b05",
   "metadata": {},
   "source": [
    "### More R Data Structures: Lists\n",
    "\n",
    "* Lists can contain elements of different types (they are heterogeneous).\n",
    "* Elements can be any object in R (vectors with different types, other lists, environments, dataframes, matrices, functions, etc.).\n",
    "* Because lists can store other lists, they allow for storing data in a recursive way (in contrast, vectors cannot contain other vectors).\n",
    "* We create lists with the `list()` function:\n",
    "\n",
    "```bash\n",
    "adh <- list(chr=\"2L\", start=14615555L, end=14618902L, name=\"Adh\") \n",
    "```\n",
    "\n",
    "Accessing elements from an R list is done using two distinct indexing operators:\n",
    "\n",
    "* **Single Brackets (`[]`)**: Use single brackets to **extract a subset of a list**, which will always return another list. For example, `my_list[1:2]` will return a new list containing the first and second elements of `my_list`.\n",
    "* **Double Brackets (`[[]]`)**: Use double brackets to **access a single element from a list**. This returns the element itself, not a list. For example, `my_list[[3]]` will return the third element from `my_list` in its original data type (e.g., a numeric vector, a data frame, etc.).\n",
    "* We can create new elements or change existing elements in a list using the familiar\n",
    "`<-`.\n",
    "* Assigning a list element the value `NULL` removes it from the list.\n",
    "\n",
    "The `str()` function in R is a useful tool for getting a compact, human-readable summary of a data structure. It's especially helpful for complex objects like nested lists or data frames.\n",
    "\n",
    "* `str()` stands for \"structure\" and it provides a concise description of an R object.\n",
    "* The output shows the **type** of each element (e.g., `List`, `num` for numeric), its **length** or dimensions, and the **first few values** it contains.\n",
    "* For nested structures, `str()` indents the output to show the hierarchy, giving you a clear view of the object's organization.\n",
    "* The `max.level` argument allows you to control how deeply `str()` explores nested objects.\n",
    "* By default, `max.level` is set to `NA`, which means it shows the full structure.\n",
    "* You can set a specific number (e.g., `str(z, max.level = 1)`) to limit the output to a certain depth, which is great for simplifying the view of very complex objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2e3a1-6a90-40e8-88cd-5dba1133fd6a",
   "metadata": {},
   "source": [
    "### Writing and Applying Functions to Lists with lapply() and sapply()\n",
    "\n",
    "#### Using lapply()\n",
    "\n",
    "```bash\n",
    "lapply(list, func_name) \n",
    "lapply(list, func_name, func_args) \n",
    "```\n",
    "\n",
    "`lapply()` has several advantages:\n",
    "* it creates the output list for us.\n",
    "* Uses fewer lines of code.\n",
    "* Leads to clearer code.\n",
    "* In some cases is faster than using a for loop.\n",
    "\n",
    "\n",
    "Using the `lapply()` function in R can be made more efficient by parallelizing it with the `mclapply()` function from the `parallel` package.\n",
    "\n",
    "* **`mclapply()` is a parallel version of `lapply()`**. It allows you to apply a function to each element of a list or vector, but it does this across multiple processor cores. This is particularly useful for tasks that are computationally intensive or \"slow.\"\n",
    "* **Basic Syntax**: You use `mclapply()` just like `lapply()`, providing the list or vector and the function you want to apply. For example, `mclapply(my_samples, slowFunction)` will run `slowFunction` on each element of `my_samples` simultaneously.\n",
    "* **Controlling Cores**: By default, `mclapply()` uses two cores or the number specified by the global `options(cores)` setting. You can explicitly set the number of cores with `options(cores = #)`.\n",
    "\n",
    "While parallelization can significantly speed up some tasks, it's not a replacement for writing clean, efficient R code. Optimizing your code first can often provide greater performance benefits than simply parallelizing a slow process.\n",
    "\n",
    "#### Writing functions\n",
    "\n",
    "General syntax for R functions:\n",
    "\n",
    "```bash\n",
    "fun_name <- function(args) {\n",
    "# body, containing R expressions\n",
    "return(value)\n",
    "}\n",
    "```\n",
    "\n",
    "* Function definitions consist of arguments, a body, and a return value.\n",
    "* Functions that contain only one line in their body can omit the braces.\n",
    "* Using `return()` to specify the return value is optional; R’s functions will automatically return the last evaluated expression in the body.\n",
    "* We could forgo creating a function with a specific name in our global environment altogether and instead use an *anonymous* function (named so because anonymous functions are functions without a name). Anonymous functions are useful when we only need a function once for a specific task. For example: `lapply(ll, function(x) mean(x, na.rm=TRUE))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d848bd9-ae39-4fe8-bf40-c6c708def3cc",
   "metadata": {},
   "source": [
    "### Digression: Debugging R Code\n",
    "\n",
    "To debug an R function, you can use the `browser()` function to pause its execution at a specific point. This allows you to:\n",
    "\n",
    "* **Inspect variables**: Check the current values of all variables.\n",
    "* **Step through code**: Execute the code line by line to see how it behaves.\n",
    "* **Examine the call stack**: View the sequence of functions that led to the current point in the code.\n",
    "\n",
    "```R\n",
    "foo <- function(x) {\n",
    "a <- 2\n",
    "browser()\n",
    "y <- x + a\n",
    "return(y)\n",
    "}\n",
    "```\n",
    "\n",
    "We use one-letter commands to control stepping through code with `browser()`. The mostly frequently used are:\n",
    "*  `n`: Execute the next line\n",
    "*  `c`: Continue running the code\n",
    "*  `Q`: Exit without continuing to run code\n",
    "\n",
    "Within `browser()`, we can view variables’ values:\n",
    "\n",
    "```R\n",
    "Browse[1]> ls() # list all variables in local scope\n",
    "[1] \"a\" \"x\"\n",
    "Browse[1]> a\n",
    "[1] 2\n",
    "```\n",
    "\n",
    "Using `options(error = recover)` is a powerful way to debug an R function that's throwing an error. This setting tells R to automatically enter an interactive debugging session whenever an error occurs.\n",
    "\n",
    "When you set `options(error = recover)` and then run a function that contains an error, the execution will pause at the exact point of the error. A menu will appear, asking you to choose which function from the call stack you want to inspect. By selecting the relevant function (e.g., `bar(2)`), you are placed at a `Browse` prompt, which is the same as if you had manually inserted a `browser()` call.\n",
    "\n",
    "From this prompt, you can:\n",
    "\n",
    "* **Inspect variables** to see their values.\n",
    "* **Step through the code** line by line.\n",
    "* **Examine the call stack** to understand the sequence of function calls.\n",
    "\n",
    "To turn this debugging mode off, simply run `options(error = NULL)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4653a98-8d7d-4cf4-a04b-5e0627793ee4",
   "metadata": {},
   "source": [
    "### More list apply functions: sapply() and mapply()\n",
    "\n",
    "#### sapply()\n",
    "* The `sapply()` function is similar to `lapply()`, except that it simplifies the results into a vector, array, or matrix.\n",
    "* `sapply()` can simplify more complex data structures than this simple list, but occasionally `sapply()` simplifies something in a strange way, leading to more headaches than it’s worth.\n",
    "\n",
    "\n",
    "#### mapply()\n",
    "* `mapply()` is a multivariate version of `sapply()`: the function you pass to `mapply()` can take in and use multiple arguments.\n",
    "* Unlike `lapply()` and `sapply()`, `mapply()`’s first argument is the function you want to apply.\n",
    "\n",
    "```R\n",
    "mapply(func_name, var1, var2) \n",
    "```\n",
    "\n",
    "* To prevent oversimplifying output, specify `SIMPLIFY=FALSE`.\n",
    "* `mapply(fun, x, y, SIMPLIFY=FALSE)` is equivalent to using the function `Map()` like `Map(fun, x, y)`, which saves some typing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4c9e6-c87e-4fa0-8583-16538cf57beb",
   "metadata": {},
   "source": [
    "### Working with the Split-Apply-Combine Pattern\n",
    "\n",
    "The \"split-apply-combine\" strategy is a common data analysis pattern in R. First, we will use R base `split()` and `lapply()` functions to do it. Next, we will use `dpylr` package to do the same operations quicker.\n",
    "\n",
    "#### Split-Apply-Combine with `split()` and `lapply()`\n",
    "\n",
    "* **Split**: The `split(x, f)` function divides a data frame or vector (`x`) into a list of subsets based on the levels of a grouping factor (`f`). Each element of the resulting list corresponds to a unique level of the factor and contains all the data belonging to that group.\n",
    "\n",
    "```R\n",
    "d_split <- split(d$depth, d$GC.binned) \n",
    "```\n",
    "\n",
    "* **Apply**: After splitting the data, you can use the `lapply()` function to apply a specific function (e.g., `mean()`, `median()`) to each element of the list created in the split step. This performs a calculation on each of the groups independently.\n",
    "\n",
    "```R\n",
    "grp_mean <- lappaly(d_split, mean) \n",
    "```\n",
    "\n",
    "* **Combine**: The final step involves combining the results of the `lapply()` operation into a single, more usable data structure, often a vector or a data frame, using `rbind()` (row binding) or `cbind()` (column binding) and `do.call()`:\n",
    "\n",
    "```R\n",
    "rbind(grp_mean[[1]], grp_mean[[2]])\n",
    "```\n",
    "\n",
    "```R\n",
    "do.call(rbind, grp_mean) # Calls rbind on all elements of grp_mean list\n",
    "```\n",
    "\n",
    "More on `split()` function:\n",
    "\n",
    "* **Grouping by Multiple Factors**: You can group data by the unique combinations of several factors by providing `split()` with a **list of factors** as its second argument.\n",
    "* **Reversing the Split**: The `unsplit()` function can reconstruct the original vector or data frame from the list created by `split()`. It requires the split list and the **original grouping factor(s)** used in the `split()` function.\n",
    "* **Splitting Entire DataFrames**: While the examples typically split single columns (vectors), `split()` can also be used to split an **entire data frame**. This is necessary when your application step (the function used in `lapply()`) requires access to **multiple columns** from the group, such as fitting a linear model (`lm()`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f2648-4628-4e99-96c1-d3f5333c0a1c",
   "metadata": {},
   "source": [
    "### Exploring Dataframes with dplyr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce112fc6-5545-459e-a713-15eba1ce27c9",
   "metadata": {},
   "source": [
    "While base R functions can perform data manipulation, the **`dplyr` package** offers a faster, simpler, and more consistent alternative for the common **split-apply-combine** data pattern.\n",
    "\n",
    "---\n",
    "\n",
    "* **Base R Limitations**: Base R functions like `split()` and `lapply()`, while versatile, are often not the fastest or simplest approach for these tasks. Convenience functions like `tapply()` and `aggregate()` often require extra steps for output cleanup.\n",
    "* **Introducing `dplyr`**: The `dplyr` package (developed by Hadley Wickham) is designed to consolidate and simplify routine data frame operations.\n",
    "* **Performance Advantage**: `dplyr` is highly performant because much of its core functionality is written in **C++** for speed.\n",
    "* **Core `dplyr` Functions**: The package centers around five basic functions for manipulating data frames:\n",
    "    * `arrange()`\n",
    "    * `filter()`\n",
    "    * `mutate()`\n",
    "    * `select()`\n",
    "    * `summarize()`\n",
    "* **Simplified Interface**: `dplyr`'s main advantage is its added **consistency, speed, and versatility**, which drastically simplifies data manipulation and allows for more effective data exploration.\n",
    "\n",
    "\n",
    "#### select()\n",
    "\n",
    "```R\n",
    "d_df <- tibble(d) # Convert d dataframe to dplyr's tibble\n",
    "select(d_df, start, end) # Select start and end columns\n",
    "select(d_df, start:depth) # Select range of columns from start to depth\n",
    "select(d_df, -start, -end) # Drop start and end columns from tibble\n",
    "select(d_df, -(start:depth)) # Drop a range of columns from tibble\n",
    "```\n",
    "\n",
    "#### filter()\n",
    "\n",
    "`filter()` is similar to subsetting dataframes using expressions like `d[d$Pi > 16 & d$percent.GC > 80, ]`, though you can use multiple statements (separated by commas) instead of chaining them with `&`:\n",
    "\n",
    "```R\n",
    "filter(d_df, Pi > 16, percent.GC > 80) \n",
    "```\n",
    "\n",
    "#### arrange()\n",
    "\n",
    "`arrange()` sorts columns, which behaves like `d[order(depth), ]`:\n",
    "\n",
    "```R\n",
    "arrange(d_df, depth) \n",
    "arrange(d_df, desc(depth)) # Sort a column in descending order\n",
    "arrange(d_df, desc(total.SNPs), desc(depth)) # Additional columns can be specified to break ties\n",
    "```\n",
    "\n",
    "#### mutate()\n",
    "\n",
    "Using `mutate()` function, we can add new columns to our dataframe:\n",
    "\n",
    "#### Chaining dplyr functions\n",
    "\n",
    "* **Problem with Sequential Operations**: Manipulating a data frame through multiple sequential steps (like selecting, filtering, and mutating) can lead to either:\n",
    "    1.  Assigning output to **intermediate variables** (which is inefficient).\n",
    "    2.  **Nesting functions** (e.g., `filter(select(...))`), which makes code difficult to read and understand (reading from the inside out).\n",
    "* **Solution: The Pipe Operator (`%>%`)**: `dplyr` uses the **pipe operator (`%>%`)** from the `magrittr` package to chain operations.\n",
    "* **How the Pipe Works**: The pipe takes the output of the expression on its left-hand side and passes it as the **first argument** of the function on its right-hand side.\n",
    "    * Example: `d_df %>% filter(percent.GC > 40)` is equivalent to `filter(d_df, percent.GC > 40)`.\n",
    "* **Benefit**: Using the pipe allows for the creation of clear, natural-reading **data-processing pipelines** that express complex data manipulation operations in a straightforward, sequential manner.\n",
    "\n",
    "#### group_by() and summarize()\n",
    "\n",
    "* We can group by one or more columns by calling `group_by()` with their names as arguments.\n",
    "* `summarize()` handles passing the relevant column to each function and automatically creates columns with the supplied argument names.\n",
    "\n",
    "The `dplyr` package offers several convenience functions designed specifically for summarizing data within groups:\n",
    "\n",
    "* **`n()`**: Returns the **total number of observations** (rows) in the current group.\n",
    "* **`n_distinct()`**: Returns the **number of unique observations** in the current group.\n",
    "* **`first()`, `last()`, and `nth()`**: These functions return specific observations from the group:\n",
    "    * `first()`: Returns the **very first observation**.\n",
    "    * `last()`: Returns the **very last observation**.\n",
    "    * `nth()`: Returns the **observation at a specified position** (e.g., the 5th row).\n",
    "\n",
    "\n",
    "One of the best features of dplyr is that all of these same methods also work with *database connections*. For example, you can manipulate a SQLite database with all of the same verbs we’ve used here. See dplyr’s databases vignette for more information on this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46604db7-4a7f-47be-9e0a-2883d0953840",
   "metadata": {},
   "source": [
    "### Working with Strings\n",
    "\n",
    "#### Key Points on R String Processing in Bioinformatics\n",
    "\n",
    "* **Necessity**: String manipulation is often required when working with bioinformatics data within R.\n",
    "* **R's Drawbacks for Text Processing**:\n",
    "    * **Memory Use**: R loads all data into memory, which is inefficient for large bioinformatics files that are better handled with **stream-based approaches**.\n",
    "    * **Clunky Functions**: R's string processing functions are considered less user-friendly and more difficult to remember compared to those in languages like Python.\n",
    "* **When to Use R's Functions**:\n",
    "    * **Practicality**: If data has **already been loaded into R** for exploration or analysis, it is simpler and more convenient to use R's built-in string functions than to switch to a separate language like Python.\n",
    "    * **Performance**: Since the initial cost of reading the data into memory has already been incurred, there's **no significant performance gain** in switching to another language just for string processing at that point.\n",
    "\n",
    "#### R functions to work with strings\n",
    "\n",
    "* `nchar()`: Retrieve the number of characters of each element of a character vector and is vectorized.\n",
    "* `grep(pattern, x)`: Returns the positions of all elements in `x` that match `pattern`:\n",
    "\n",
    "```R\n",
    "> re_sites <- c(\"CTGCAG\", \"CGATCG\", \"CAGCTG\", \"CCCACA\") \n",
    "> grep(\"CAG\", re_sites) \n",
    "# [1] 1 3\n",
    "```\n",
    "\n",
    "By default, `grep()` uses POSIX extended regular expressions, so we could use more sophisticated patterns:\n",
    "\n",
    "```R\n",
    "> grep(\"CT[CG]\", re_sites) \n",
    "#[1] 1 3\n",
    "```\n",
    "\n",
    "* **Controlling Regular Expression Dialect**:\n",
    "    * **Perl Compatible Regular Expressions (PCRE)**: Enable this modern, powerful dialect using the argument `perl=TRUE`. This is often required for special symbols like `\\d` (which matches any digit).\n",
    "    * **Fixed String Matching**: Use `fixed=TRUE` to treat the pattern as a literal string, disabling the interpretation of special regular expression characters.\n",
    "* **Writing Precise Patterns**: To avoid matching unwanted strings (e.g., matching \"6\" but excluding \"16\"), you must use a **restrictive regular expression**.\n",
    "    * **Example**: The pattern `[^\\\\d]6` matches any non-digit character (`[^\\\\d]`) immediately followed by the number `6`, successfully filtering out entries like \"chr16\".\n",
    "* **Backslash Escaping**: When using regular expressions in R strings, you often need to **double-escape** backslashes (e.g., `\\\\d`) to ensure the correct pattern is passed to the engine.\n",
    "\n",
    "```R\n",
    ">chrs <- c(\"chrom6\", \"chr2\", \"chr6\", \"chr4\", \"chr1\", \"chr16\", \" chrom8\")\n",
    "> grep(\"[^\\\\d]6\", chrs, perl=TRUE)\n",
    "#[1] 1 3\n",
    "> chrs[grep(\"[^\\\\d]6\", chrs, perl=TRUE)]\n",
    "#[1] \"chrom6\" \"chr6\"\n",
    "```\n",
    "\n",
    "* `regexpr(pattern, x)`: Unlike `grep()`, `regexpr(pattern, x)` returns where in each element of `x` it matched `pattern`. If an element doesn’t match the pattern, `regexpr()` returns –1. For example:\n",
    "\n",
    "```R\n",
    "> pos <- regexpr(\"[^\\\\d]6\", chrs, perl=TRUE)\n",
    "# [1] 5 -1 3 -1 -1 -1 -1\n",
    "# attr(,\"match.length\")\n",
    "# [1] 2 -1 2 -1 -1 -1 -1\n",
    "# attr(,\"useBytes\")\n",
    "# [1] TRUE\n",
    "```\n",
    "\n",
    "* You can access attributes with the function `attributes()`:\n",
    "\n",
    "```R\n",
    "atrributes(pos)$match.length\n",
    "```\n",
    "\n",
    "* `substr()`: `substr(x, start, stop)` takes a string `x` and returns the characters between `start` and `stop`.\n",
    "\n",
    "* `sub()`: `sub(pattern, replacement, x)` replaces the first occurrence of `pattern` with `replacement` for each element in character vector `x`. Like `regexpr()` and `grep()`, `sub()` supports `perl=TRUE` and `fixed=TRUE`:\n",
    "\n",
    "```R\n",
    "> sub(pattern=\"Watson\", replacement=\"Watson, Franklin,\",\n",
    "x=\"Watson and Crick discovered DNA's structure.\")\n",
    "# [1] \"Watson, Franklin, and Crick discovered DNA's structure.\" \n",
    "```\n",
    "\n",
    "* `paste()`: `paste()` takes any number of arguments and concatenates them together using the separating string specified by the `sep` argument (which is a space by default). Like many of R’s functions, `paste()` is vectorized:\n",
    "\n",
    "```R\n",
    "> paste(\"chr\", c(1:22, \"X\", \"Y\"), sep=\"\")\n",
    "# [1] \"chr1\" \"chr2\" \"chr3\" \"chr4\" \"chr5\" \"chr6\" \"chr7\" \"chr8\" \"chr9\"\n",
    "# [10] \"chr10\" \"chr11\" \"chr12\" \"chr13\" \"chr14\" \"chr15\" \"chr16\" \"chr17\" \"chr18\"\n",
    "# [19] \"chr19\" \"chr20\" \"chr21\" \"chr22\" \"chrX\" \"chrY\"\n",
    "```\n",
    "\n",
    "* `strsplit()`: `strsplit(x, split)` splits string `x` by `split`. Like R’s other string processing functions, `strsplit()` supports optional `perl` and `fixed` arguments. For example:\n",
    "\n",
    "```R\n",
    "> leafy <- \"gene=LEAFY;locus=2159208;gene_model=AT5G61850.1\"\n",
    "> strsplit(leafy, \";\")\n",
    "# [[1]]\n",
    "# [1] \"gene=LEAFY\"\n",
    "# \"locus=2159208\"\n",
    "# \"gene_model=AT5G61850.1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005138da-7bc9-4745-a89a-5292d62e3ef0",
   "metadata": {},
   "source": [
    "### Developing Workflows with R Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f5870-0869-4b68-a8ba-1d540669c9e3",
   "metadata": {},
   "source": [
    "#### Control Flow: if, for, and while\n",
    "\n",
    "The basic syntax of `if`, `for`, and `while` are:\n",
    "\n",
    "```R\n",
    "if (x == some_value) {\n",
    "# do some stuff in here\n",
    "} else {\n",
    "# else is optional\n",
    "}\n",
    "for (element in some_vector) {\n",
    "# iteration happens here\n",
    "}\n",
    "while (something_is_true) {\n",
    "# do some stuff\n",
    "}\n",
    "```\n",
    "\n",
    "* `ifelse()`: Vectorized version of `if`: Rather than control program flow, `ifelse(test, yes, no)` returns the yes value for all TRUE cases of test, and no for all FALSE cases. For example:\n",
    "\n",
    "```R\n",
    "> x <- c(-3, 1, -5, 2)\n",
    "> ifelse(x < 0, -1, 1)\n",
    "# [1] -1 1 -1 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b21f8f7-3e3e-443a-8b87-ae34600074d7",
   "metadata": {},
   "source": [
    "### Working with R Scripts\n",
    "\n",
    "You can run R scripts from R using the function `source()`. For example, to execute an R script named \"my_analysis.R\" use:\n",
    "\n",
    "```R\n",
    "> source(\"my_analysis.R\")\n",
    "```\n",
    "\n",
    "Alternatively, we can execute a script in batch mode from the command line with:\n",
    "\n",
    "```bash\n",
    "$ Rscript --vanilla my_analysis.R\n",
    "```\n",
    "\n",
    "* **Recommended Flag**: Use `Rscript --vanilla` when running scripts from the command line.\n",
    "* **Default Behavior (Avoided)**: By default, `Rscript` restores a previously saved R environment and then saves the current environment upon completion.\n",
    "* **Irreproducible Results**: Restoring past saved states (`.RData` files) makes results **irreproducible** because the script's outcome depends on local files and context, not just the code itself.\n",
    "* **Debugging Nightmare**: Saved environments can severely complicate **debugging** efforts by introducing unexpected variables and states.\n",
    "* **Benefit of `--vanilla`**: It ensures R starts in a clean state without loading any past saved environments, guaranteeing that the analysis runs independently and is more easily debugged.\n",
    "\n",
    "* `commandArgs()`: Retrieves command-line arguments passed to your script. For example, this simple R script just prints all arguments:\n",
    "\n",
    "```R\n",
    "## args.R -- a simple script to show command line args\n",
    "args <- commandArgs(TRUE)\n",
    "print(args)\n",
    "```\n",
    "\n",
    "We run this with:\n",
    "\n",
    "```bash\n",
    "$ Rscript --vanilla args.R arg1 arg2 arg3\n",
    "[1] \"arg1\" \"arg2\" \"arg3\"\n",
    "```\n",
    "\n",
    "#### Reproducibility and sessionInfo()\n",
    "\n",
    "* **The Problem**: Results from R analyses can change over time due to **updates in R and package versions**, causing **reproducibility headaches**.\n",
    "* **The Solution**: At a minimum, you must **always record the versions of R and all packages** used for an analysis.\n",
    "* **How to Record Versions**: R makes this process easy with the built-in function **`sessionInfo()`**, which provides a detailed summary of the current R environment.\n",
    "* **Advanced Solutions**: Addressing these versioning issues is an active area of development, with tools like the **`packrat`** package available for more comprehensive environment management.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05191e-3df2-45ec-aa8b-888f21d5c375",
   "metadata": {},
   "source": [
    "### Workflows for Loading and Combining Multiple Files\n",
    "\n",
    "* `list.files()`: Is used to list all files within a specified directory.\n",
    "\n",
    "* **Filtering with Regex**: The function optionally accepts a **regular-expression pattern** via the `pattern` argument, which is used to select only files that match the expression.\n",
    "* **Best Practice**: It's highly recommended to make the regex pattern **as restrictive as possible** (e.g., `pattern=\"hotspots.*\\\\.bed\"`) to prevent accidentally loading incorrect or extraneous files that might end up in the data directory.\n",
    "\n",
    "* **Example**: To load all `.bed` files for a specific dataset from a \"hotspots\" directory, you would use a command like:\n",
    "\n",
    "```R\n",
    "list.files(\"hotspots\", pattern=\"hotspots.*\\\\.bed\") \n",
    "```\n",
    "\n",
    "Some details in above command:\n",
    "\n",
    "`pattern = \"hotspots.*\\\\.bed\"`: This argument provides a regular expression (regex) used to filter the files found in the directory. Only files whose names match this pattern will be returned:\n",
    "* `hotspots`: Matches the literal string \"hotspots\".\n",
    "* `.*`: Matches any character (.) zero or more times (*). This is a flexible wildcard that allows for any characters (like _chr1) to be between \"hotspots\" and the file extension.\n",
    "* `\\\\.`: Matches the literal period (.) before the file extension. The double backslash is necessary because the single backslash escapes the period, telling R to treat it as a literal character rather than the regex wildcard.\n",
    "* `bed`: Matches the literal file extension \"bed\".\n",
    "\n",
    "* `list.files()` also has an argument that returns full relative paths to each file:\n",
    "\n",
    "```R\n",
    "> hs_files <- list.files(\"hotspots\", pattern=\"hotspots.*\\\\.bed\", full.names=TRUE)\n",
    "> hs_files\n",
    "# [1] \"hotspots/hotspots_chr1.bed\" \"hotspots/hotspots_chr10.bed\"\n",
    "```\n",
    "\n",
    "Now, let's read multiple bed files and combined them into a single dataframe:\n",
    "\n",
    "```R\n",
    "# Create header row for combined bed dataframe.\n",
    "bedcol <- c(\"chr\", \"start\", \"end\")\n",
    "# Define a function to read tab-delimited bed file.\n",
    "loadFile <- function(x) read.delim(x, header=FALSE, col.names=bedcol)\n",
    "# Apply loadFile for each elements of hs_files.\n",
    "hs <- lapply(hs_files, loadFile)\n",
    "# Concatenate dataframes into one big dataframe.\n",
    "hsd <- do.call(rbind, hs)\n",
    "# Remove row names\n",
    "row.names(hsd) <- NULL\n",
    "```\n",
    "\n",
    "Often, we need to include a column in our dataframe containing meta-information about files that’s stored in each file’s filename. As a simple example of this, let’s pretend we did not have the column chr in our hotspot files and needed to extract this information from each filename using sub(). We’ll modify our `loadFile()` function accordingly:\n",
    "\n",
    "```R\n",
    "loadFile <- function(x) {\n",
    "# read in a BED file, extract the chromosome name from the file,\n",
    "# and add it as a column\n",
    "df <- read.delim(x, header=FALSE, col.names=bedcols)\n",
    "df$chr_name <- sub(\"hotspots_([^\\\\.]+)\\\\.bed\", \"\\\\1\", basename(x))\n",
    "df$file <- x\n",
    "df\n",
    "}\n",
    "```\n",
    "\n",
    "**Bonus note**: You can use `fix()` function to fix a function, which was defined on rstudio's console. It would open up a new window with called function so you can edit the function and save it.\n",
    "\n",
    "Processing files this way is very convenient for large files, and is even more powerful because it’s possible to parallelize data processing by simply replacing `lapply()` with `mclapply()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30917911-a77b-49d3-9a3b-0ca95f7500ee",
   "metadata": {},
   "source": [
    "### Exporting Data\n",
    "\n",
    "To export data frames from R to plain-text files, you use the `write.table()` function. However, its default settings often need adjustment for standard data export.\n",
    "\n",
    "#### Key Points for Using `write.table()`\n",
    "\n",
    "  * **Required Arguments**: The first two arguments are the **data frame/matrix** to export and the **file path** (`file`) where it should be saved.\n",
    "  * **Adjusting Defaults (Standard Practice)**: To create a clean, tab-delimited file without extra quotes or row numbers, you typically set the following arguments:\n",
    "      * `quote = FALSE`: **Disables quotation marks** around character and factor columns.\n",
    "      * `row.names = FALSE`: **Excludes R's internal row numbers** from the output file.\n",
    "      * `sep = \"\\t\"`: **Sets the column separator to a tab** (`\\t`) for creating a tab-delimited file.\n",
    "      * `col.names = TRUE`: **Includes column headers** (though this is often the default, it's good practice to ensure it).\n",
    "  * **Writing Compressed Files (Gzip)**: You can directly write compressed (Gzipped) files by passing an **open file connection** to the `file` argument instead of a simple string path. This is achieved using the `gzfile()` function, which is useful for integration with Unix tools.\n",
    "\n",
    "**Example of Best Practice Export:**\n",
    "\n",
    "```r\n",
    "write.table(mtfs, file=\"hotspot_motifs.txt\", quote=FALSE, sep=\"\\t\", row.names=FALSE, col.names=TRUE) \n",
    "```\n",
    "\n",
    "```r\n",
    "hs_gzf <- gzfile(\"hotspots.txt.gz\")\n",
    "write.table(mtfs, file=hs_gzf, quote=FALSE, row.names=FALSE, col.names=TRUE, sep='\\t')\n",
    "```\n",
    "\n",
    "**Serialization**: Encoding and saving objects to disk in a way that allows them to be restored as the original object is known as serialization. R’s functions for saving and loading R objects are `save()` and `load()`.\n",
    "\n",
    "```r\n",
    "tmp <- list(vec=rnorm(4), df=data.frame(a=1:3, b=3:5))\n",
    "save(tmp, file=\"example.Rdata\")\n",
    "rm(tmp) # remove the original 'tmp' list\n",
    "load(\"example.Rdata\") # this fully restores the 'tmp' list from file\n",
    "str(tmp)\n",
    "# List of 2\n",
    "# $ vec: num [1:4] -0.655 0.274 -1.724 -0.49\n",
    "# $ df :'data.frame':\n",
    "# 3 obs. of 2 variables:\n",
    "# ..$ a: int [1:3] 1 2 3\n",
    "# ..$ b: int [1:3] 3 4 5\n",
    "```\n",
    "\n",
    "The `save.image()` function is a convenient way to quickly save your entire R workspace, including all objects currently defined. When combined with `savehistory()`, which saves the commands you've run, these two functions can be used in a rush to store all of your recent work.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
